<h1>Regression Therapy - Contentful Testing</h1>
<img style='float: right; margin: 1.5em; margin-top: 0' alt="Contentful bear" src="http://contentful.rubyforge.org/bear.jpg" />
<p><small>
(This article is a fleshing out of a ten-slides-in-ten-minutes talk that
<a href="http://anthonybailey.tumblr.com/post/5687247">I gave in July 2007</a> 
at <a href="http://www.amazondc.com/">work</a>.)
</small></p>

<h2>1. Introduction</h2>
<p>
Regression testing is usually seen as the poorer cousin of "proper" domain-abstracted assertion-based testing.
Often rightly so!
</p><p>
However, with the right support in place, I have found that this form of testing can work very well in certain contexts.
</p><p>
This article addresses one such context: testing the view content generated by a web app.
I discuss the background,
then present a concrete example in the form of a plug-in for <a href="http://rubyonrails.org/">Rails</a>.
</p>

<hr />

<h2>2. Three reasons to test</h2>
<p>
For the purpose of this discussion, I identify three overlapping but distinguishable uses of tests in software development.
</p>

<h3>To preserve existing good behaviour</h3>
<p>
Tests can be used to maintain known good behaviour, preventing accidental bad changes (also known as "regressions".)
The tests provide a safety net during refactorings, and enfore a Hippocratic  "first, do no harm" oath during other work.
</p><span style='background: #eee; font-size: 120%; font-weight: bold; color: green'>
....................................<font color='red'>!</font>..<font color='red'>!</font>...........................<font color='red'>!</font>...........
</span><p>
The test stays green whilst all is well. A red bar tells us that we've messed up and broken something.
</p>

<h3>To drive intended changes</h3>
<p>
Tests can be used to change (often, to add) behaviour, providing context to an intended good change.
The archetypal example is classic <abbrev title='Test-driven development'>TDD</abbrev>,
creating tests first in order to define the problem,
and to guide the design and implementation of a solution.
</p><span style='background: #eee; font-size: 120%; font-weight: bold; color: green'>
&gt;<font color='red'>&gt;</font>&gt;<font color='red'>&gt;</font>&gt;<font color='red'>&gt;</font>&gt;<font color='red'>&gt;</font>&gt;<font color='red'>&gt;</font>&gt;<font color='red'>&gt;</font>&gt;<font color='red'>&gt;</font>&gt;<font color='red'>&gt;</font>&gt;<font color='red'>&gt;</font>&gt;<font color='red'>&gt;</font>&gt;<font color='red'>&gt;</font>&gt;<font color='red'>&gt;</font>&gt;<font color='red'>&gt;</font>&gt;<font color='red'>&gt;</font>&gt;<font color='red'>&gt;</font>&gt;<font color='red'>&gt;</font>&gt;<font color='red'>&gt;</font>&gt;
</span><p>
New tests flash red and are put back to green by introducing production code.
</p>

<h3>To understand emergent change</h3>
<p>
A less often discussed use of testing is to explore and validate emergent behaviour.
</p><p>
In a complex system it can be hard to prejudge or predict every knock-on effect
of a deliberate change to one part of that system.
Tests can provide a context for understanding and controlling such changes and consequences.
</p><span style='background: #eee; font-size: 120%; font-weight: bold; color: green'>
.....<font color='red'>!!??<small>?<small>?<small>?<small>?</small></small></small></small></font>...................<font color='red'>!!??<small>?<small>?<small>?<small>?</small></small></small></small></font>............<font color='red'>!!??<small>?<small>?<small>?<small>?</small></small></small></small></font>..............
</span><p>
In this way of working, changes cause flashes of red that are observed
and then often approved,
updating expectations to recolor things back to green again.
</p>

<hr />

<h2>3. Three ways to test</h2>
<p>
Next I'll categorize three methods of testing,
paying particular attention to their use in the context of testing view content.
</p>

<h3>Live testing</h3>
<p>
In a scandalously unrepeatable manner that sacrifices reliable coverage, we can test by hand and verify by eye.
</p><p>
Drive the web app through the browser and see if looks right.
We all do this.
It shouldn't be sniffed at; it is genuinely useful because it is so cheap.
However, once the system gets sufficiently complex, it doesn't hold
<abbrev title="Does WATIR hold it? Perhaps! I'm not the right person to ask.">water</abbrev>.
I won't consider manual testing further in this article.
</p>

<p style='margin-top: 2em'>
To automate testing, we have to be able to provoke the generation of view content that we can then test.
Assuming a good web app framework that allows us to do this (no small thing, but not the topic of interest today),
there are then two means of testing the content.
</p>

<h3>Assertion testing</h3>
<p>
We can explcitly check individual desired properties of the the resulting content.
</p>

<h3>Regression testing</h3>
<p>
Or, we can compare the content in its entirety against a previously validated known good copy.
</p>

<p style='margin-top: 2em'>
I'll now discuss in greater detail the relative merits of testing view content through assertion and regression.
</p>
 
<hr />

<h2>4. <code style='font-size: 120%'>assert_equals(expected, test_method)</code></h2>
<p>
Assertion tests are prevalent in contemporary developer testing, with good reason.
They tend to be very effective, given sufficient investment &ndash;
we need to express the properties that care about succinctly,
and at an appropriate level of abstraction within the domain.
</p><p>
The Rails web framework has evolved a best-of-breed solution for assertion testing view content
in the form of <code>assert_select</code>.
It uses CSS selectors to locate content, and neatly expresses the conditions it should satisfy.
Here's a simple example:
</p><blockquote style='font-family: monospace; font-size: 120%; padding: 1em; background: #0dd; color: black'><pre>
class CartExampleTest
  def test_total
    get "/store/add_to_cart", :id => rails_book.id
    <span style='background: #cff; font-weight: bold'>assert_select "div#cart tr.total td:last-of-type", "$39.95"</span>
  end
end
</pre></blockquote><p>
This is pretty nice.
But it doesn't escape some downsides of assertion testing
which happen to be particularly troublesome for view content.
</p>

<h3>Coverage is selective</h3>
<p>
We can only capture the behaviors that we think to test for.
The importance of many properties of view content are not obvious until we've accidentally changed them.
</p>

<h3>Exploration is expensive</h3>
<p>
Assertion tests are generally great for catching regressions and for driving changes.
But they are poor for my third type of test use, that of exploring change.
The developer has to run around rebalancing the books,
fixing up test expectations to agree with the unexpected consequences of a change.
</p>

<h3>Explicitness is verbose</h3>
<p>
Many aspects of the view are worth caring about.
It takes too much code to express them all explicitly;
translation, even into a well-designed and succinct language, still takes time.
The most concise summary of all the properties of a piece of content is the content itself&hellip;
</p>

<hr />

<h2>5. Regression (past life)</h2>
<p>
&hellip;which leads us to our next alternative.
</p><p>
Regression tests work by checking current content against expected content.
We test by comparing the entirety of what we generate against some previously approved copy.
The expected content might be quoted verbatim in the test; more often it is stored in a file.
</p><blockquote style='font-family: monospace; font-size: 120%; padding: 1em; background: #0dd; color: black'><pre>
class CartExampleTest
  def test_total
    get "/store/add_to_cart", :id => rails_book.id
    <span style='background: #cff; font-weight: bold'>assert_equals File.new('expected.html').read, @response</span>
  end
end
</pre></blockquote><p>
This is clearly very cheap to express, and capturing existent good behaviour needs no translation: just a copy and paste of the current results.
</p><p style='margin-top: 2em'>
But like assertion testing, regression testing view content comes with some downsides.
</p>

<h3>Tests don't come first</h3>
<p>
Again this form of testing is good for two of the three uses of testing that I identified.
It is ideal for exploring changes,
and unsurprisingly it catches regressions.
But, it is very awkward to drive new behavior.
</p><p>
However, this problem is not serious in the context of view content.
Although it would not be plausible to test-drive the generation of content through regression testing,
it is not clear that one would ever want to.
View content tends to come into existence in a concrete form,
designed or composed in toto
rather than being built up one abstract essence at a time.
Even for those who usually love to test first, test-last of view content does not seem so detestable.
</p><p style='margin-top: 2em'>
The main problem with regression testing is that it is very expensive if we act naively in response to diffs.
There are two common pain points.
</p>
 
<h3>Tests are brittle and fragile</h3>
<p>
Comparing against a complete text copy means that we see every change, even ones we don't actually care about.
Every difference needs explicit attention.
</p>

<h3>Tests are usually noisy</h3>
<p>
Because there is no abstraction, one change may break many tests.
Similar differences need attention in multiple places.
</p><p>
These workflow costs multiply as the system under regression test grows.
Investing in the abstraction of assertion tests is usually preferrable.
Even in the domain of view content, regression tests will prove too costly if we do not work to make them less so.
</p>

<hr />

<h2>6. <strike>Regression</strike> Contentful testing</h2>
<p>
So: let's attempt to address the problems, and turn regression testing into contentful testing.
</p>

<h3>Lessen the noise</h3>
<p>
Information can be defined as any difference that makes a difference.
The diffs that don't are the noise in regression tests that we want to reduce.
</p><dl>
<dt>Ignore insignificant change</dt>
<dd><p>
Some textual changes in HTML source
(for example, certain whitespace in content;
and formatting, quoting, capitalization and attribute order within the mark-up itself)
won't affect how the content is displayed.
</p><p>
These can be ignored by allowing a little abstraction back in.
We can still use standard text-based diff tools,
but to compare unique text representations of <abbrev title='Document Object Model'>DOM</abbrev>-normalized content.
</p></dd>
<dt><abbrev title="Don't repeat yourself">DRY</abbrev> up which content is tested</dt>
<dd><p>
Rather than see the same diff to the same repeated content over and over,
we can focus regression tests on those parts of content that vary across our testcases.
</p></dd>
</dl>

<h3>Smooth the workflow</h3>
<p>
In good automation fashion, we will make the common tasks in the workflow as cheap and as easy as we can.
</p><p>
It has to be simple
</p><ul>
<li>to create a new regression test,</li>
<li>to inspect diffs from the expected content when changes occur, and</li>
<li>to accept the changes once they have been checked over and seen to be OK.</li>
</ul><p>
And, this needs to work well in batch.
We should be able to detect, review and accept changes in many tests at a time when need be.
</p>

<h3>The Contentful Rails plug-in</h3>
<p>
I put together a plug-in that tries to do these things within Rails.
</p><blockquote style='font-family: monospace; font-size: 120%; padding: 1em; background: black; color: cyan'><pre>
% script/plugin install svn://rubyforge.org/var/svn/contentful
</pre></blockquote><p>
The plug-in was evolved in, then extracted from, a small spare-time web application.
I've since re-used it successfully in other Rails projects.
If you write Rails applications, you can read more and download the plug-in at the
<a href='http://contentful.rubyforge.org/'>Contentful website</a>.
</p><p>
For this discussion, Contentful is simply a single concrete example
of a general approach I believe should translate across language boundaries,
or from my Rake automation commands into your favorite <abbrev title='Interactive development environement'>IDE</abbrev>.
</p>

<hr />

<h2>7. Capturing content to create tests</h2>
<p>
With Contentful plugged-in, we can check the content generated in a test by saying <code>assert contentful</code>.
</p><blockquote style='font-family: monospace; font-size: 120%; padding: 1em; background: #0dd; color: black'><pre>
class CartExampleTest
  def test_total
    get "/store/add_to_cart", :id => rails_book.id
    <span style='background: #cff; font-weight: bold'>assert_contentful</span>
  end
end
</pre></blockquote><p>
Then when we run the test for the first time, the test passes
- and it generates the expected content from the current content, as a side effect.
In accord with Rails' culture of convention over configuration,
we locate the expected content in a standard place,
derived from the name of the test.
</p><blockquote style='font-family: monospace; font-size: 120%; padding: 1em; background: black; color: cyan'><pre>
% rake test
Started
...................................!...............
Finished in 3.487022 seconds.

  1) Contentful Notification:
test_total(CartExampleTest):
Generated /depot/<span style='color: #cff; font-weight: bold'>test/contentful/cart_example/total/expected.html</span>
</pre></blockquote><p>
To avoid duplication, we can focus on a particular subset of the content using a <abbrev title='Cascading Style Sheet'>CSS</abbrev> selector. This allows us to ignore components that are common across all our views, such as navigation sidebars and the like.
</p><blockquote style='font-family: monospace; font-size: 120%; padding: 1em; background: #0dd; color: black'><pre>
class CartExampleTest
  def test_total
    get "/store/add_to_cart", :id => rails_book.id
    <span style='background: #cff; font-weight: bold'>select_contentful "div#cart"</span>
  end
end
</pre></blockquote>
<blockquote style='font-family: monospace; font-size: 120%; padding: 1em; background: black; color: cyan'><pre>
% rake test
Started
...................................!...............
Finished in 3.494442 seconds.

  1) Contentful Notification:
test_total(CartExampleTest):
Generated /depot/test/contentful/cart_example/total/<span style='color: #cff; font-weight: bold'>div#cart.</span>expected.html
</pre></blockquote>

<hr />

<h2>8. Detecting changes and inspecting diffs</h2>
<p>
Now our tests are up, we should set them running.
(Running everything is the norm,
but Contentful will build and execute a suite containing only its own tests if asked.
I'll show that here.)
</p><p>
Here's what happens when we've broken something:
</p><blockquote style='font-family: monospace; font-size: 120%; padding: 1em; background: black; color: cyan'><pre>
% rake test:content
Testing expectations in test/contentful
Started
..F.....
Finished in 0.808864 seconds.

  1) Failure:
test_total(CartExampleTest)
<span style='color: #cff; font-weight: bold'>diff test/contentful/cart_example/total/*.to_diff</span>
to see the content change
</pre></blockquote><p>
The failing test will have written a temporary <code>changed.html</code> file next to <code>expected.html</code>.
Additionally it generates a second pair of files
(<code>expected.to_diff</code> and <code>changed.to_diff</code>)
which are the same HTML DOMs,
but with some added line-breaks and other normalization to make them usefully comparable using a standard text diff.
<p></p>
(Whenever a test passes, the stale three files get cleaned away.)
</p><p>
As well as using the suggested command-line to examine an individual failure,
we can inspect all current diffs by running a single command.
</p><blockquote style='font-family: monospace; font-size: 120%; padding: 1em; background: black; color: cyan'><pre>
% rake test:diff
Finding changes in test/contentful
! Diff in cart_example/total/changed.html
91c91
&lt; &lt;td id="total"&gt;
&lt; Total
---
&gt; &lt;td id="total" class="grand"&gt;
&gt; Grand Total
! Diff in another_example/something_else/changed.html
<var>[etc...]</var>
</pre></blockquote><p>
(Additionally, if we want to focus on a subset of all the current changes,
we can do so by running within a subdirectory of <code>test/contentful</code>.)
</p>

<hr />

<h2>9. Accepting change</h2>
<p>
If a set of changes are good,
then often we can tell this by casting an eye over the diffs and observing a plausible pattern.
</p><p>
(Sometimes one can grep the diffs for extra certainty.
For bonus points, script anything you find yourself doing by hand three times!)
</p><p>
If all looks good, we want to accept a bunch of changes.
</p><blockquote style='font-family: monospace; font-size: 120%; padding: 1em; background: black; color: cyan'><pre>
% rake test:accept
Finding changes in test/contentful/cart_example
! Accepting cart_example/total/changed.html
! Accepting another_example/something_else/changed.html
</pre></blockquote><p>
That was a bit better than opening up an editor and copying and pasting the content, right?
</p><p>
(Again we can refine our acceptance to a subset of changes by running within a subdirectory.)
</p><p>
Also, since expected content is generated when absent,
we can alternatively use the file system to our advantage,
and update expectations by removing particular subdirectories and then re-running tests.
</p><blockquote style='font-family: monospace; font-size: 120%; padding: 1em; background: black; color: cyan'><pre>
% rm test/contentful/further/specific/*
<var>[etc...]</var>
Generated /depot/test/contentful/further/specific/expected.html
</pre></blockquote>

<hr />

<h2>10. Making a vice out of a virtue</h2>
<p>
Personally, I really like my content tests to be a permanent part of the test suite.
Once the workflow is smooth, I find them well worth their maintenence cost.
I like the total coverage; they allow serendipidous discovery of changes I didn't consider.
</p><p>
However, even if you won't buy the entire bridge that I'm trying to sell you, perhaps I can interest you in a strut:
use the virtues of contentful testing as a <a href='http://www.artima.com/weblogs/viewpost.jsp?thread=171323'>vice</a>.
(Sorry for the UK spelling. Translate it into the US "vise" if you like, but you'll spoil my pun.)
</p><p>
Suppose we want to perform a pervasive refactoring. For example,
</p><ul>
<li>to <a href='http://anthonybailey.livejournal.com/29792.html'>change</a> the templating framework we're using, or</li>
<li>to factor out a set of view helpers and partials.</li>
</ul><p>
Big changes are risky.
It would be nice to temporarily pin everything about current content tightly down in place whilst we work.
When using Contentful, then we can add a bonus content assertion to every existing functional and integration test
by setting a single Rails config flag in <code>environment.rb</code>:
</p><blockquote style='font-family: monospace; font-size: 120%; padding: 1em; background: #0dd; color: black'><pre>
CONTENTFUL_AUTO = true
</pre></blockquote><p>
Running tests once generates expectations and locks down all the current content.
Then we can perform our refactoring under their full protection.
When done, we unset the config flag and delete the temporary expectations before checking in the safely refactored code.
</p><blockquote style='font-family: monospace; font-size: 120%; padding: 1em; background: black; color: cyan'><pre>
% wget <a style='color: cyan' href='http://contentful.rubyforge.org/'>http://contentful.rubyforge.org/</a>
</pre></blockquote><p>
Thanks for reading! Comments are most welcome.
</p>

<hr />
